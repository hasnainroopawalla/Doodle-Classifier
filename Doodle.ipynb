{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doodle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasnainroopawalla/Doodle-Classifier/blob/master/Doodle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVw_3p-alvaJ",
        "colab_type": "text"
      },
      "source": [
        "**Download the 'classes.txt' file containing all 345 classes\n",
        "OR\n",
        "Download the '100_classes.txt' containing 100 classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Q1QFIYDJWE",
        "colab_type": "code",
        "outputId": "233e35e6-461e-49d4-bda7-044a556be757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/all_classes.txt'\n",
        "!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-13 17:20:17--  https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘100_classes.txt’\n",
            "\n",
            "100_classes.txt     100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-13 17:20:22 (210 MB/s) - ‘100_classes.txt’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IAKpXQNDkMB",
        "colab_type": "code",
        "outputId": "5f8cfbf8-5d5b-48a8-946d-b370b3f869ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#f = open(\"all_classes.txt\",\"r\")\n",
        "f = open(\"100_classes.txt\",\"r\")\n",
        "classes = f.readlines()\n",
        "f.close()\n",
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip', 'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet', 'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider', 'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', 'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth', 'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses', 'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball', 'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent', 'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', 'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', 'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet', 'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhFbpgqRmHEO",
        "colab_type": "text"
      },
      "source": [
        "**Create a folder called 'data' to store all dataset images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rakGyTcdDxcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMDXNrnLnw2A",
        "colab_type": "text"
      },
      "source": [
        "**Download images for 345 (or 100) classes and store it in the 'data' folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aQgqKd2D0Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "class_num = 0\n",
        "for c in classes:\n",
        "  class_num +=1\n",
        "  print(class_num,c)\n",
        "  cls_url = c.replace('_', '%20')\n",
        "  path = base+cls_url+'.npy'\n",
        "  urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syYT7OA2nsdg",
        "colab_type": "text"
      },
      "source": [
        "**Import all necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKBk5_uRFGdU",
        "colab_type": "code",
        "outputId": "b2e1d23f-5240-4e72-ef30-31ecc10f6eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwqAP2aWq-DH",
        "colab_type": "text"
      },
      "source": [
        "**Select 4000 (or any number) random images for each class and split data into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FC8QuIMFH2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class = 16000):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "        print(len(class_names))\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    ## Randomize dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #Split dataset into train and test\n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSy1Fzs_FQd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn9dvz_VrK51",
        "colab_type": "text"
      },
      "source": [
        "**Print number of classes and train images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN0vgz3gGiwV",
        "colab_type": "code",
        "outputId": "21c8d361-175a-42db-de3d-caf80c51042a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of Classes:',num_classes)\n",
        "print('Train Images:',len(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Classes: 100\n",
            "Train Images: 1280000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjuKDVNwrtV5",
        "colab_type": "text"
      },
      "source": [
        "**Print random image (and its class) from training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc_0-oiWGxDg",
        "colab_type": "code",
        "outputId": "9b135fbc-63a6-4294-b2b0-0207eb600b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "donut\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdXwziDSr6ip",
        "colab_type": "text"
      },
      "source": [
        "**Reshape and normalize each train and test image to 28x28 if not already**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8TYoWVTG4WY",
        "colab_type": "code",
        "outputId": "19a4cce1-cb23-4b61-f5ec-7268599f9c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = 28\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(x_train.shape[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXqwoZVqsBn7",
        "colab_type": "text"
      },
      "source": [
        "**Define Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCPYXLZ_G6V2",
        "colab_type": "code",
        "outputId": "b088900e-cde0-409a-eadd-622f81625ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax'))  # The number here should be equal to number of classes\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 110,052\n",
            "Trainable params: 110,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdotnt7vsJCf",
        "colab_type": "text"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIIFyYZbG81y",
        "colab_type": "code",
        "outputId": "5d88425d-1b5e-4440-aaf0-5c2370cfe502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=1, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1152000 samples, validate on 128000 samples\n",
            "Epoch 1/10\n",
            "1152000/1152000 [==============================] - 24s 21us/sample - loss: 1.3460 - top_k_categorical_accuracy: 0.8713 - val_loss: 0.9998 - val_top_k_categorical_accuracy: 0.9183\n",
            "Epoch 2/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.9162 - top_k_categorical_accuracy: 0.9273 - val_loss: 0.8854 - val_top_k_categorical_accuracy: 0.9292\n",
            "Epoch 3/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.8294 - top_k_categorical_accuracy: 0.9352 - val_loss: 0.8247 - val_top_k_categorical_accuracy: 0.9361\n",
            "Epoch 4/10\n",
            "1152000/1152000 [==============================] - 24s 21us/sample - loss: 0.7846 - top_k_categorical_accuracy: 0.9395 - val_loss: 0.7927 - val_top_k_categorical_accuracy: 0.9381\n",
            "Epoch 5/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7553 - top_k_categorical_accuracy: 0.9420 - val_loss: 0.7777 - val_top_k_categorical_accuracy: 0.9396\n",
            "Epoch 6/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7335 - top_k_categorical_accuracy: 0.9441 - val_loss: 0.7520 - val_top_k_categorical_accuracy: 0.9410\n",
            "Epoch 7/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7175 - top_k_categorical_accuracy: 0.9453 - val_loss: 0.7468 - val_top_k_categorical_accuracy: 0.9419\n",
            "Epoch 8/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7049 - top_k_categorical_accuracy: 0.9465 - val_loss: 0.7409 - val_top_k_categorical_accuracy: 0.9427\n",
            "Epoch 9/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6951 - top_k_categorical_accuracy: 0.9473 - val_loss: 0.7416 - val_top_k_categorical_accuracy: 0.9423\n",
            "Epoch 10/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6873 - top_k_categorical_accuracy: 0.9480 - val_loss: 0.7402 - val_top_k_categorical_accuracy: 0.9417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc9c5914a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGz1C7ILHMG2",
        "colab_type": "code",
        "outputId": "ca4a4a26-65ca-460d-efa9-5f05a19c425e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 94.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9kBq83g9WNT",
        "colab_type": "text"
      },
      "source": [
        "**Use random test images to test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrKVB4dyHTi_",
        "colab_type": "code",
        "outputId": "44592478-fbe1-46e6-9b20-ef013e6da1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze(),cmap='Greys_r') \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sword', 'knife', 'airplane', 'baseball_bat', 'pencil']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEcKGv8orocEgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnfDstQYHYKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CrQiDcHrvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8LQwlHCYsz",
        "colab_type": "text"
      },
      "source": [
        "### **Prediction on Input image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5qnIXp6-Lki",
        "colab_type": "text"
      },
      "source": [
        "**Load the Model and Class Names for predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ybfXWETWzLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('100_classes_16000_per_class.h5')\n",
        "\n",
        "class_names = ['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip',\n",
        "               'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet',\n",
        "               'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider',\n",
        "               'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', \n",
        "               'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth',\n",
        "               'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses',\n",
        "               'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball',\n",
        "               'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent',\n",
        "               'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', \n",
        "               'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', \n",
        "               'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet',\n",
        "               'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MzmmBsB-OXh",
        "colab_type": "text"
      },
      "source": [
        "**Make predictions on any input image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCxKthnCJTcP",
        "colab_type": "code",
        "outputId": "a57a4b05-17fc-4d1b-8218-e053be1eee1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "img = load_img('b.png', target_size=(28,28))\n",
        "img = ImageOps.invert(img)\n",
        "plt.imshow(img) \n",
        "img_tensor = img_to_array(img)\n",
        "\n",
        "plt.imshow(img_tensor/255)\n",
        "\n",
        "img_tensor = cv2.cvtColor(img_tensor, cv2.COLOR_BGR2GRAY) # Convert channel to 1 (grayscale)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=2) # Add last channel as 1  (28,28) to (28,28,1)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0) # Add 1 more channel at start to specify number of input images (1,28,28,1)\n",
        "img_tensor /= 255. \n",
        "\n",
        "#print(img_tensor.shape)\n",
        "\n",
        "pred = model.predict(img_tensor)[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "objs = [class_names[x] for x in ind]\n",
        "print(objs)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bed', 'bench', 'table', 'bridge', 'rainbow']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvYgcV_I0eQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1cc1884c-1e30-441a-97a7-db4d042e8cab"
      },
      "source": [
        "!pip install lime\n",
        "import lime \n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/e0/60070b461a589b2fee0dbc45df9987f150fca83667c2f8a064cef7dbac6b/lime-0.1.1.37.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.6)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (6.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (42.0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.1)\n",
            "Building wheels for collected packages: lime, progressbar\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.1.1.37-cp36-none-any.whl size=284277 sha256=74a2b627850adde3c19067ecbfbefe4c41bbb0b3eb994ad7e144a894f51db87d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/38/e7/50d75d4fb75afa604570dc42f20c5c5f5ab26d3fbe8d6ef27b\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12073 sha256=61485ce1f4d7c9cfc21ca38e3ba57129d2e99e1e4284445e284b82cf96a8ab7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built lime progressbar\n",
            "Installing collected packages: progressbar, lime\n",
            "Successfully installed lime-0.1.1.37 progressbar-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGbFvZ-kI5aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path='./dataset/test/sunrise/'+sun_rise[7]  ### repalce path with the path for image u want to be expalined\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img = image.img_to_array(img)/255\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title('Image')\n",
        "plt.show()\n",
        "\n",
        "img = np.expand_dims(img, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}